##### Basic Points
Brains can:
- recognise images/objects/abstract symbolic information
- retrieve information based on partial descriptions
- organise information

Computers can:
- do arithmetic and arithmetic logic
- deductive logic
- retrieve information based on arbitrary features

![[Pasted image 20231120123721.png]]

##### Perceptron
A perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurones to learn and process elements in the training set one at a time.

![[Pasted image 20231120123738.png]]

A perceptron is a neural network composed of a single layer feed-forward network using threshold activation functions. Feed-forward means that all the interconnections between the layers propagate forward to the next layer.

The simple perceptron uses the threshold activation function with a bias and thus has a binary output. The binary output perceptron has two possible outputs: 0 and 1. It is trained by supervised learning and can only classify input patterns that are linearly separable.

Training is accomplished by initialising the weights and bias to small random values and then presenting input data to the network. The output ($y$) is compared to the target output ($t = 0$ or $t = 1$), and the weights are adapted according to Hebb's training rule.

The simple single layer perceptron can separate linearly separable inputs but will fail if the inputs are otherwise. One such example of linearly non-separable inputs is the exclusive-or (XOR) problem. Linearly non-separable patterns, such as those of the XOR problem, can be separated with multilayer networks.

> [!Definition] Limitations Summary
> Perceptrons are limited in that they can only separate linearly separable patterns and that they only have a binary output.

Many of the limitations of the simple perceptron can be solved with multi-layer architectures, non-binary activation functions, and more complex training algorithms.

##### Multiple Perceptron
Multilayer perceptrons with threshold activation functions are not that useful because they can't be trained with the perceptron learning rule and since the functions are not differentiable, they can't be trained with gradient descent algorithms.

###### Activation Functions
The activate function is generally non-linear. Linear functions are limited because the output is simply proportional to the input.
![[Pasted image 20231030172857.png]]

![[Pasted image 20231030173051.png]]
*Multilayer architecture*

##### Feedforward Neural Networks
The basic structure of a feedforward neural network is as follows:
![[Pasted image 20231030173803.png|test]]
The learning rule modifies the weights according to the input the patterns are presented with. In a sense, ANNs learn by example as do their biological counterparts.

When the desired outputs are known we have supervised learning or learning with a teacher.
![[Pasted image 20231030174005.png]]
*Multiple layers in the feedforward network*

##### Overview of the back-propagation
1. a set of examples for training the network is assembled. Each case consists of a problem statement (which represents the input into the network) and the corresponding solution (which represents the desired output from the network).
2. the input data is entered into the network via the input layer.
3. each neurone in the network processes the input data with the resultant values steadily "percolating" through the network, layer by layer, until a result is generated by the output layer
4. the actual output of the network is compared to expected output for that particular input. This results in an *error value*. The connection weights in the network are gradually adjusted, working backwards from the output layer, through the hidden layer, and to the input layer, until the correct output is produced. Fine tuning the weights in this way has the effect of teaching the network how to produce the correct output for a particular input $\implies$ the network *learns*

![[Pasted image 20231120123913.png]]

##### The Learning Rule
The delta rule is often utilised by the most common class of ANNs called 'backpropagational neural networks'.
![[Pasted image 20231120124343.png]]
When a neural network is initially presented with a pattern it makes a random guess as to what it might be. It then sees how far its answer was from the actual one and makes an appropriate adjustment to its connection weights.

###### Inside the Delta Rule
Backpropagation performs a gradient descent within the solution's vector space towards a global minimum. The error surface itself is a hyperparaboloid but is seldom smooth as is depicted in the graphic below.
![[Pasted image 20231120124536.png]]
Indeed, in most problems, the solution space is quite irregular with numerous pits and hills which may cause the network to settle down in a *local minimum* which is not the best overall solution.


### Multilayer Neural Network
Neural networks with one or more hidden layers are called *multilayer neural networks* or multilayer perceptrons (MLP). Normally, each hidden layer of a network uses the same type of activation function.

The output activation function is either sigmoidal or linear. The output of a sigmoidal neurone is constrained $[-1, 1]$ for a hyperbolic tangent and $[0, 1]$ for a logarithmic sigmoidal neurone.

A linear output neurone is not constrained and can output a value of any magnitude.

![[Pasted image 20231120124855.png]]
*Sigmoid function vs hyperbolic tangent function*

It has been proved that the standard feedfoward multilayer perceptron (MLP) with a single non-linear hidden layer (sigmoidal neurones) can approximate any continuous function to any desired degree of accuracy over a compact set.

In order to be a universal approximation, the hidden layer of a multilayer perceptron is usually a sigmoidal neurone. A linear hidden layer is rarely used because any two linear transformations can be represented as one linear transformation (matrix algebra).

#### Standard MLNN
![[Pasted image 20231120125755.png]]
The output for a single hidden layer MLP with three inputs, three hidden hyperbolic tangent neurones and two linear output neurones can be calculated using matrix algebra:

$y = w_2 \times \text{tanh}(w_1 \times x + b_1) + b_2$ 
$= \begin{bmatrix} 0.5 & -0.25 & 0.33 \\ 0.2 & -0.75 & -0.5 \end{bmatrix} \text{tanh} \left(\begin{bmatrix} 0.2 & -0.7 & 0.9 \\ 2.3 & 1.4 & -2.1 \\ 10.2 & -10.2 & 0.3 \end{bmatrix} \begin{bmatrix} 2 \\ 4 \\ 6 \end{bmatrix} + \begin{bmatrix} 0.5 \\ 0.2 \\ -0.8 \end{bmatrix}\right) + \begin{bmatrix} 0.4 \\ -1.2 \end{bmatrix}$ 

By using dummy nodes and embedding the biases into the weight matrix we can use a more compact notation:

$y = w_2 \times [1; \text{tanh}(w_1 \times [1;x])]$ 
$= \begin{bmatrix} 0.4 & 0.5 & -0.25 & 0.33 \\ -1.2 & 0.2 & -0.75 & -0.5 \end{bmatrix} \left\{ \text{tanh}\left(\begin{array} \text{1} \\ \begin{bmatrix} 0.5 & 0.2 & -0.7 & 0.9 \\ 0.2 & 2.3 & 1.4 & -2.1 \\ -0.8 & 10.2 & -10.2 & 0.3 \end{bmatrix} \end{array} \begin{bmatrix} 1 \\ 2 \\ 4 \\ 6 \end{bmatrix}\right) \right\}$ 

#### Backpropagation
Backpropagation (BP) is a general method for iteratively solving for a multilayer perceptrons' weights and biases.

It uses a steepest descent technique which is very stable when a small learning rate is used, but has slow convergence properties.

Several methods for speeding up BP have been used including momentum and a variable learning rate.

##### The Chain Rule
The Chain Rule is derivative of the activation functions. For logistic, hyperbolic tangents, and linear functions, the derivates are as follows:

| Name | Function | Derivative |
|------|----------|------------|
| Linear | ${\Phi}(I) = I$ | $\dot{\Phi}(I) = 1$ |
| Logistic | ${\Phi}(I) = \frac{1}{1 + e^{-al}}$ | $\dot{\Phi}(I) = {\alpha}{\Phi}(I)(1 - {\Phi}(I))$ |
| Tanh | ${\Phi}(I) = \frac{e^{al} - e^{-al}}{e^{al} + e^{-al}}$ | $\dot{\Phi}(I) = \alpha(1 - {\Phi}(I)^2)$ |

$\alpha$ is called the slope parameter. Usually $\alpha$ is chosen to be 1 but other slopes may be used. This formulation for the derivative makes the computation of the gradient more efficient since the output ${\Phi}(I)$ has already been calculated in the forward pass.

##### Backpropagation for a Multilayer Neural Network
The backpropagation algorithm is an optimisation technique designed to minimise an objective function. The most commonly used objective function is the squared error which is defined as:
${\varepsilon}^2 = [T_q - {\Phi}_{qk}]^2$ 

![[Pasted image 20231120132830.png]]
In this notation, the layers are labeled i, j, and k; with m, n and r neurones respectively; and the neurones in each layer are indexed h, p, and q respectively.
- $\text{x}$ = input value
- $\text{T}$ = target output value
- $\text{w}$ = weight value
- $\text{I}$ = internal activation
- $\Phi$ = neurone output
- $\varepsilon$ = error term

The outputs for a two layer network with both layers using a logistic activation function are calculated by the equation:
$\Phi = \text{logistic}\{\text{w2} \times [\text{logistic}(\text{w1} \times \text{x} + \text{b1})] + \text{b2}\}$
- $\text{w1}$ = first layer weight matrix
- $\text{w2}$ = second layer weight matrix
- $\text{b1}$ = first layer bias vector
- $\text{b2}$ = second layer bias vector

The input vector can be augmented with a dummy node representing the bias input. This dummy input of 1 is multiplied by a weight corresponding to the bias value. This results in a more compact representation of the above equation:
$\Phi = \text{logistic}\left\{\text{W2} \times \left[\begin{array} \text{1} \\ \text{logistic}(\text{W1} \times \text{X}) \end{array}\right]\right\}$
- $\text{X}$ = $[1, \text{x}]'$ (augmented input vector)
- $\text{W1}$ = $[\text{b1}, \text{w1}]$
- $\text{W2}$ = $[\text{b2}, \text{w2}]$

Note that a dummy hidden node (= 1) also needs to be inserted into the equation.

For a two input network with two hidden nodes and one output node, we have:
- $\text{x}$ = $\begin{bmatrix} 1 \\ x_1 \\ x_2 \end{bmatrix}$
- $\text{W1}$ = $\begin{bmatrix} b_{11} & w_{11} & w_{21} \\ b_{12} & w_{12} & w_{22} \end{bmatrix}$
- $\text{W2}$ = $\begin{bmatrix} b_2 & w_{11} & w_{12} \end{bmatrix}$

#### Summary
The output layer weights are changed in proportion to the negative gradient of the squared error with respect to the weights. These weight changes can be calculated using the chain rule.

The standard error is equal to
$\text{E} = \frac{(\text{Y}_3 - {\text{Y}_t})^2}{2}$
- $Y_3$ = output error
- $Y_t$ = given error ($Y_1 \rightarrow Y_3$)

What follows is quick derivation for a two layer network with each layer having logistic activation functions. Note that the target outputs can only have a range of $[0, 1]$ for a network with a logistic output layer.

${\Delta}w_{pq.k} = -{\eta}_{p.q}\frac{{\partial}{\varepsilon}^2}{{\partial}w_{pq.k}}$
$= -{\eta}_{p.q} \times \frac{{\partial}{\varepsilon}^2}{{\partial}{\Phi}_{q.k}} \times \frac{{\partial}{\Phi}_{q.k}}{{\partial}I_{q.k}} \times \frac{{\partial}I_{q.k}}{{\partial}w_{pq.k}}$
$= -{\eta}_{p.q} \times (-2)[T_q - {\Phi}_{q.k}] \times {\Phi}_{q.k}[1 - {\Phi}_{q.k}] \times {\Phi}_{p.j}$ 
$= -{\eta}_{p.q} \times {\delta}_{pq.k} \times {\Phi}_{p.j}$ 
and
${\delta}_{pq.k} = 2[T_q - {\Phi}_{q.k}]{\Phi}_{q.k}[1 - {\Phi}_{q.k}]$

The weight update equation for the output neurones is:
$w_{pq.k}(N + 1) = w_{pq.k}(N) - {\eta}_{p.q} \times {\delta}_{pq.k} \times {\Phi}_{p.j}$ 

The hidden layer outputs have no target values. Therefore, a procedure is used to backpropagate the output layer errors to the hidden layer neurones in order to modify their weights to minimise the error.

To accomplish this, we start with the equation for the gradient with respect to the weights and use the chain rule.

${\Delta}w_{hp.j} = -{\eta}_{h.p} \frac{{\partial}{\varepsilon}^2}{{\partial}w_{hp.j}}$
$= -{\eta}_{h.p} \displaystyle\sum_{q=1}^r \frac{{\partial}{\varepsilon}^2}{{\partial}w_{hp.j}}$
$= -{\eta}_{h.p} \displaystyle\sum_{q=1}^r \times \frac{{\partial}{{\varepsilon}_q}^2}{{\partial}{\Phi}_{q.k}} \times \frac{{\partial}{\Phi}_{q.k}}{{\partial}I_{q.k}} \times \frac{{\partial}I_{q.k}}{{\partial}{\Phi}_{p.j}} \times \frac{{\partial}{\Phi}_{p.j}}{{\partial}I_{p.j}} \times \frac{{\partial}I_{p.j}}{{\partial}w_{hp.j}}$
$\frac{{\partial}{{\varepsilon}_q}^2}{{\partial}{\Phi}_{q.k}} = (-2)[T_q - {\Phi}_{q.k}]$
$\frac{{\partial}{\Phi}_{q.k}}{{\partial}I_{q.k}} = {\alpha}{\Phi}_{q.k}[1 - {\Phi}_{q.k}]$
$\frac{{\partial}I_{q.k}}{{\partial}{\Phi}_{p.j}} = w_{pq.k}$
$\frac{{\partial}{\Phi}_{p.j}}{{\partial}I_{p.j}} = {\alpha}{\Phi}_{p.j}[1 - {\Phi}_{p.j}]$
$\frac{{\partial}I_{p.j}}{{\partial}w_{hp.j}} = x_h$

which leads to

$\frac{{\partial}{\varepsilon}^2}{{\eta}w_{hp.j}} = \displaystyle\sum_{q=1}^r(-2)[T_q - {\Phi}_{q.k}] \times {\alpha}{\Phi}_{q.k}[1 - {\Phi}_{q.k}] \times w_{pq.k} \times {\alpha}{\Phi}_{p.j}[1 - {\Phi}_{p.j}] \times x_h$
$= \displaystyle\sum_{q=1}^r{\delta}_{pq.k} \times w_{pq.k} \times {\alpha}{\Phi}_{p.j}[1 - {\Phi}_{p.j}] \times x_h$
${\delta}_{hp.j} = {\delta}_{pq.k}w_{pq.k}\frac{{\partial}{\Phi}_{p.j}}{{\partial}I_{p.j}}$
$w_{hp.j}(N + 1) = w_{hp.j}(N) - {\eta}_{hp}x_h{\delta}_{hp.j}$
