### Context-free grammar
A context-free grammar is a grammar with productions
	$A \rightarrow \alpha$
$A \in N$ and $\alpha \in (N \cup T)^\ast$. A language is context-free if it is generated by a context-free grammar.
- Context-free languages $\Leftrightarrow$ non-deterministic pushdown automata
- There are languages which can be recognised by NPDA but not by DPDA, eg palindromes

### CFL and natural/computer languages
The idea of context-free languages is to describe the grammar of English in terms of their block structure and recursively build up from smaller phrases.

An essential property of these block structures is that logical units never overlap. A context-free grammar provides a simple and mathematically precise mechanism, and can also be used for describing the structure of the programming languages.

> [!faq] Example: English fragments
> ![[Pasted image 20231017091621.png]]
> For the sentence: "the boy touches the girl with the flower."

### Derivation and a parse tree
We know which of the meanings is intended if we know how the string was derived. A parse (derivation) tree can be used to describe a derivation starting with initial symbol and working down towards the string.
- start symbol is the tree's root (<Sentence\>)
- for a production $X \rightarrow Y_1 ... Y_n$ add children $Y_1, ... Y_n$ to the node $X$ (e.g <Cmplx-Noun\> $\rightarrow$ <Article\> <Noun\>)
- terminals at the leaves (e.g boy, girl), non-terminals at the interior nodes (e.g <Article\>)

> [!faq] First derivation tree
> ![[Pasted image 20231017095101.png]]

> [!faq] Second derivation tree
> ![[Pasted image 20231017095122.png]]

Both are valid trees!

> [!faq] Example
> **Consider a grammar fragment for simple arithmetic expressions, where $E$ is the only non-terminal:**
> 	$E \rightarrow E - E \:|\: 0 \:|\: 1 \:|\: 2 \:|\: 3 \:|\: 4 \:|\: 5 \:|\: 6 \:|\: 7 \:|\: 8 \:|\: 9$
> 	
> Examples of strings which we can derive are: $4 -8, 9 - 1, 5 - 6 - 9 - 2, ...$
> Such strings can be given a meaning (or a value in this case), e.g $4 - 8 = -4, 9 - 1 = 8, ...$
> 	
> When we want to explain "the meaning of a string" we need to know how the string was derived.

However, we can construct multiple CORRECT parse trees from the same string, e.g the string $2 - 4 - 6$:
![[Pasted image 20231017100737.png]]
This results in $-8$.
![[Pasted image 20231017100751.png]]
However, this results in $+4$ - another correct solution.

> [!faq] Example: IF THEN ELSE
> **Consider the grammar with the productions ($S$ in the start non-terminal):**
> 	$S \rightarrow \text{if}\: b\: \text{then}\: S\: \text{else}\: S \:|\: \text{if}\: b\: \text{then}\: S \:|\: a$ 
> then the string "if b then if b then a else a" has two different parser trees:
> ![[Pasted image 20231017100928.png]]
> Both results are possible!
> 
> If the grammar is ambiguous, the compiler has no way to determine which of two meanings to use.

### Ambiguous grammar
The grammar
	$E \rightarrow E - E \:|\: 0 \:|\: 1 \:|\: 2 \:|\: 3 \:|\: 4 \:|\: 5 \:|\: 6 \:|\: 7 \:|\: 8 \:|\: 9$
is an example of an ambiguous grammar ($\exists$ a string from that language with two different parse trees).

> [!info] Definition
> A grammar is unambiguous if each string has only ONE parse tree (or equivalently: there is only one left-most (or right-most) derivation for each string). Otherwise, the grammar is ambiguous.

There are no general techniques for handling ambiguity, and it is impossible to automatically convert an ambiguous grammar to an unambiguous one.

In some cases, the grammar can be modified to generate the same language and to remove ambiguity. There are various techniques for that, e.g "using parentheses".

In the case of the IF THEN ELSE example, we can
- match each *else* to innermost unmatched *if*
- another approach to remove ambiguity:
	  $S_1 \rightarrow \text{if}\: b\: \text{then}\: S_1\: \text{else}\: S_1\: \text{end} \:|\: \text{if}\: b\: \text{then}\: S_1\: \text{end}\: \:|\: a$ 

### Parsing
Parsing is a process in which:
- the input string is checked whether it has correct syntax e.g $2 - - 8$ is not a correct string from the language
- a parse tree is built which captures the internal structure of the string - it records how the input can be derived from the start symbol
So we want more than just a YES/NO answer of an NPDA which accepts a given context-free language.

Parsing can be down in two ways:
#### Top-down parsing
Top-down parsing constructs a derivation by starting with the grammar's start symbol and working towards the string.

> [!faq] Example
> The grammar 
> 	$E \rightarrow E - E \:|\: 0 \:|\: 1 \:|\: 2 \:|\: 3 \:|\: 4 \:|\: 5 \:|\: 6 \:|\: 7 \:|\: 8 \:|\: 9$
> and the input string $2 - 4 - 6$
> ![[Pasted image 20231017101846.png]]
> If, after following ever logical lead, we can't generate the string then the string cannot be parsed (sometimes difficult to decide).

#### Bottom-up parsing
Bottom-up parsing constructs a derivation by starting with the string and working backwards to the start symbol.

> [!faq] Example
> The grammar 
> 	$E \rightarrow E - E \:|\: 0 \:|\: 1 \:|\: 2 \:|\: 3 \:|\: 4 \:|\: 5 \:|\: 6 \:|\: 7 \:|\: 8 \:|\: 9$
> and the input string $2 - 4 - 6$:
> 
> $2 - 4 - 6 \Leftarrow E - 4 - 6 \Leftarrow E - E - 6$
> &#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160$\Leftarrow E - 6 \Leftarrow E - E$
> &#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160&#160$\Leftarrow E$
> 
> If all combinations fail, then the string cannot be parsed.

#### Summary of parsing techniques
Top-down parsers:
- start at the root of the parse tree and grow toward leaves
- pick a production and try to match the input
- bad "pick" $\implies$ may need to backtrack
- some grammars are backtrack-free

Bottom-up parsers:
- start at the leaves and grow towards root
- as input is consumed, encode possibilities in an internal state
- start in a state valid for legal first tokens
- bottom-up parsers handle a large class of grammars

### $LL(k)$ and $LR(k)$ grammars
The best candidates for languages that are efficient are languages based on $LL(k)$-grammars or $LR(k)$-grammars for any $k \geq 0$.

- $LL(k)$-grammars are based on $LL(k)$ parsers for top-down parsing.
- $LR(k)$-grammars are based on $LR(k)$ parsers for bottom-up parsing.

#### $LL(k)$ parsing
What does $LL(k)$ mean for parsing?
- first $L$: an input string is parsed from left to right
- second $L$: only the leftmost derivations of the input string are considered
- $k$ is the number of look-ahead symbols needed to decide parsing (we don't need to know all symbols before making a decision about derivation)

> [!faq] Example: $LL(1)$ grammar
> The grammar $S \rightarrow aSc \:|\: b$ with the initial non-terminal $S$ for the language $LL(1) = \{a^nbc^n, n \geq 0\}$ is an example of an $LL(1)$ grammar.
> 
> Consider the input string $aabcc$. Looking only at "the current symbol" of the input, do we know *uniquely* which leftmost derivation has to be used?
> 
> 1. Start at the beginning of the string ($a$ from $aabcc$) - $a \implies S \rightarrow aSc$ production must be used.
>    ![[Pasted image 20231021145722.png]]
> 2. The next symbol is $a$ again, so $a \rightarrow aSc$ must be used again.
>    ![[Pasted image 20231021145827.png]]
> 3. Moving to the next symbol $b \implies S \rightarrow b$.
>    ![[Pasted image 20231021145905.png]]
>    
>So a production could be chosen looking only at the current symbol.

> [!faq] Example: $LL(2)$ grammar
> The grammar $S \rightarrow AB, A \rightarrow aA \:|\: a, B \rightarrow bB \:|\: c$ with the initial non-terminal $S$ for the language $\{a^mb^nc, m \geq 0\}$ is an example of $LL(2)$ grammar.
> 
> Two productions begin with $a$, and we can't determine which one to use without looking ahead at the next symbol. But this is enough, so this must be an $LL(2)$ grammar.
> 
> How can we derive $aabbc$?
> 1. It must begin with $S \rightarrow AB$.
> 2. The input string is $aabbc \rightarrow a$ is our first symbol.
>    We can't tell whether our next rule is $A \rightarrow aA$ or $A \rightarrow a$, so we must look at the symbol ahead. Since it is followed by $a$, we can see the production used must be $A \rightarrow aA$.
> 3. The second $a$, followed by a $b$, must be produced with $A \rightarrow a$.
> 4. The first $b$, followed by a $b$, must be produced with $B \rightarrow bB$.
> 
> It is clear that in this way, we can get a full derivation just by looking at, at most, two symbols ahead.
> $S \Rightarrow AB \Rightarrow aAB \Rightarrow aaB \Rightarrow aabB \Rightarrow aabbB \Rightarrow aabbc$

**Summary of $LL(k)$ grammar**
- the grammars are unambiguous and are a subset of deterministic context-free languages
- the computation power of an $LL(k)$ grammar grows as $k$ increases.
  e.g. the syntax of the $C$ language is too complex to be described by an $LL(1)$ grammar, however it could be done by an $LL(2)$ grammar
- $LL(1)$ grammar are very popular, as they are easy to parse


#### $LR(k)$ grammars
The languages based on $LR(k)$-grammars can be parsed bottom-up.
- $L$ in $LR(k)$ - we 'scan' the string from left to right, but produce a right-most derivation $R$ in reverse, which is unique
- this involves reversing the productions and is more difficulty to see through

Knuth proved **$LR(1)$ languages are exactly $LR(k)$ languages which are exactly deterministic context-free languages (DCFL).**

Deterministic context-free grammars are a proper subset of the context-free grammars - they can be recognised by the DPDA. DCFGs are always unambiguous.

> [!faq] Example: $LR(0)$-grammars
> Let's consider the language $L = \{ab^{2n+1}c \:|\: n \geq 0\}$ with the grammars
> 	$S \rightarrow aAc$
> 	$A \rightarrow Abb \:|\: b$
> 
> How can we parse $abbbbbc$?
> 1. Working from the bottom up, we look for the right-hand side of a production in the string. The first one we find is $b$, which we replace with $A$:
> 	   $a_|b_|bbbbc \Leftarrow a_|A_|bbbbc$
> 2. We repeat the process with this new string, and the first one we find is $Abb$:
> 	   $a_|Abb_|bbc \Leftarrow a_|A_|bbc$
> 3. We also find that
> 	   $a_|Abb_|c \Leftarrow a_|A_|c$
> 	 and
> 	  $a_|A_|c \Leftarrow S$
> 	  
> Inverting this, we find
> 	$S \Rightarrow aSc \Rightarrow aAbbc \Rightarrow aAbbbbc \Rightarrow abbbbbc$

### Summary
- context-free languages $\Leftrightarrow$ non-deterministic pushdown automata
- virtually all programming language constructs can be represented by context-free grammars $\implies$ parsers (NDFA) can be constructed for these languages
- most programming languages have deterministic parsers


